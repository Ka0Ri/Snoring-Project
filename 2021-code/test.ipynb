{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import numpy as np\n",
                "from scipy.io import wavfile\n",
                "from scipy.signal import resample_poly\n",
                "from scipy.signal import resample_poly, firwin, freqz, lfilter, cheby1, butter\n",
                "# import matplotlib.pyplot as plt\n",
                "from scipy import fftpack\n",
                "import os\n",
                "from random import randrange\n",
                "from scipy import signal\n",
                "from scipy.fftpack import fft, dct\n",
                "from scipy import stats\n",
                "\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "path = os.getcwd()\n",
                "print(path)\n",
                "sampling_rate = 4000"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "/home/vips/share/Vu/Snoring-Project/new_code\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Preprocess data"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def cut(frames, n_sample):\n",
                "    samples = []\n",
                "    for frame in frames:\n",
                "        for i in np.arange(0, frame.shape[0], 1):\n",
                "            s = int(n_sample*(i))\n",
                "            e = int(n_sample*(i + 1))\n",
                "            if(e > frame.shape[0]):\n",
                "                break\n",
                "            samples.append(frame[s:e])\n",
                "    return np.array(samples)\n",
                "\n",
                "def framing(f, spr, t):\n",
                "    n_sample = t*spr//1000\n",
                "    for f in os.listdir(path + \"/sound/data/non_snoring/\"):\n",
                "        print(f)\n",
                "        fs, data = wavfile.read(path + \"/sound/data/non_snoring/\" + f)\n",
                "        sound = cut(np.array([data]), n_sample)\n",
                "        np.save(path + \"/1s/\" + f, np.array(sound))\n",
                "        print(sound.shape[:])\n",
                "    return sound.shape[:]\n",
                "    \n",
                "def cut_newdata(path, f):\n",
                "    #read wave file, under wav extension\n",
                "    fs, data = wavfile.read(path + f + \".wav\")\n",
                "    y = resample_poly(data, 4000, fs).astype(np.int16)\n",
                "    fs = 4000\n",
                "    print(\"sampling rate \", fs, \"length \", 1./3600*y.shape[0]/fs)\n",
                "    start_time = (0*60)*fs\n",
                "    end_time = (427*60)*fs\n",
                "    step = 15*60*fs\n",
                "    while (start_time < end_time):\n",
                "        s = start_time\n",
                "        e = start_time + step\n",
                "        if(e > end_time):\n",
                "            e = end_time\n",
                "        temp = y[int(s):int(e)]\n",
                "        start_time = e\n",
                "        name = str(int(s/(60*fs))) + \"-\" + str(int(e/(60*fs))) + \".wav\"\n",
                "        wavfile.write(path + f + \"/\" + name, fs, temp)\n",
                "\n",
                "def randomly_cut_30s(path):\n",
                "    fs, data = wavfile.read(path + \"1-13.wav\")\n",
                "    y = resample_poly(data, 4000, fs).astype(np.int16)\n",
                "    fs = 4000\n",
                "    print(\"sampling rate \", fs, \"length \", 1./3600*y.shape[0]/fs)\n",
                "    l = y.shape[0]\n",
                "    length = fs*30\n",
                "    for i in range(100):\n",
                "        start = randrange(l-fs*30)\n",
                "        sub = y[start:start+length]\n",
                "        wavfile.write(path + \"1-13/\" + str(i) + \".wav\", fs, sub)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Feature extraction for ML"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def nor(data):\n",
                "    mi = np.min(data)*1.0\n",
                "    ma = np.max(data)*1.0\n",
                "    data = (2*data - ma - mi)/(ma - mi)\n",
                "    return data\n",
                "\n",
                "\n",
                "def stas_feature(data, spr):\n",
                "    l = data.shape[0]  \n",
                "    #fft\n",
                "    yf = fft(data)\n",
                "    yf = yf[:l//2]\n",
                "    energy = 1/(l)*np.abs(yf)\n",
                "    #feature\n",
                "    r0 = 50*l//spr\n",
                "    r1 = 250*l//spr\n",
                "    r2 = 500*l//spr\n",
                "    r3 = 800*l//spr\n",
                "     \n",
                "    mean = np.mean(energy)\n",
                "    sd = np.std(energy)\n",
                "    mean1 = np.mean(energy[r0:r1])/mean\n",
                "    sd1 = np.std(energy[r0:r1])/sd\n",
                "    mean2 = np.mean(energy[r1:r2])/mean\n",
                "    sd2 = np.std(energy[r1:r2])/sd\n",
                "    mean3 = np.mean(energy[r2:r3])/mean\n",
                "    sd3 = np.std(energy[r2:r3])/sd\n",
                "    return [mean1, mean2, mean3, sd1, sd2, sd3]\n",
                "\n",
                "def stas_feature4(data, spr):\n",
                "    l = data.shape[0]\n",
                "    #fft\n",
                "    yf = fft(data)\n",
                "    yf = yf[:l//2]\n",
                "    energy = 1/(l)*np.abs(yf)\n",
                "    energy_scale = energy/scaling_factor\n",
                "    # energy_scale = np.log(energy + 1)\n",
                "    energy_scale = energy_scale - np.min(energy_scale)\n",
                "    #feature\n",
                "    r0 = 50*l//spr\n",
                "    r1 = 250*l//spr\n",
                "    r2 = 500*l//spr\n",
                "    r3 = 800*l//spr\n",
                "    # mean = np.mean(energy_scale)\n",
                "    # sd = np.std(energy_scale)\n",
                "    mean1 = np.mean(energy_scale[r0:r1])\n",
                "    sd1 = np.std(energy_scale[r0:r1])\n",
                "    mean2 = np.mean(energy_scale[r1:r2])\n",
                "    sd2 = np.std(energy_scale[r1:r2])\n",
                "    mean3 = np.mean(energy_scale[r2:r3])\n",
                "    sd3 = np.std(energy_scale[r2:r3])\n",
                "    return [mean1, mean2, mean3]\n",
                "\n",
                "def stas_feature6(data, spr):\n",
                "    l = data.shape[0]  \n",
                "    #fft\n",
                "    yf = fft(data)\n",
                "    yf = yf[:l//2]\n",
                "    energy = 1/(l)*np.abs(yf)\n",
                "    energy_scale = energy/scaling_factor\n",
                "    # energy_scale = np.log(energy + 1)\n",
                "    energy_scale = energy_scale - np.min(energy_scale)\n",
                "    #feature\n",
                "\n",
                "    mean = np.mean(energy_scale)\n",
                "    sd = np.std(energy_scale)\n",
                "    skewness = stats.skew(energy_scale)\n",
                "    kutoris = stats.kurtosis(energy_scale)\n",
                "    median = np.median(energy_scale)\n",
                "    \n",
                "    return [mean, median]\n",
                "\n",
                "def create_filter_banks(n_filters, spr, l):\n",
                "    #create filter banks\n",
                "    filter_banks = np.zeros([n_filters, l//2])\n",
                "    lower_f = 50\n",
                "    upper_f = spr//2\n",
                "    band = np.linspace(2595*np.log(1 + lower_f/700), 2595*np.log(1 + upper_f/700), n_filters + 2)\n",
                "    band = 700*(np.exp(band/2595) - 1)\n",
                "    band = np.round(band*1000/(2*spr))\n",
                "    for i in range(1, n_filters + 1):\n",
                "        start = int(band[i - 1])\n",
                "        end = int(band[i + 1])\n",
                "        mid = int(band[i])\n",
                "        filter_banks[i - 1][start:mid] = (1.0*np.arange(start, mid) - start)/(mid - start)\n",
                "        filter_banks[i - 1][mid:end] = (end - 1.0*np.arange(mid, end))/(end - mid)\n",
                "    return filter_banks\n",
                "\n",
                "def MFCC(data, filter_banks):\n",
                "    #fft\n",
                "    sig = data\n",
                "    l = sig.shape[0]\n",
                "    yf = fft(sig)\n",
                "    yf = yf[:l//2]\n",
                "    energy = (1/l)*np.abs(yf)\n",
                "    n_filters = filter_banks.shape[0]\n",
                "    #filter\n",
                "    coeff = []\n",
                "    for i in range(0, n_filters):\n",
                "        coeff.append(np.log(np.sum(filter_banks[i] * energy)))\n",
                "    dct_coeff = dct(np.array(coeff))\n",
                "    return dct_coeff[:n_filters//2]\n",
                "\n",
                "filter_banks = create_filter_banks(26, sampling_rate, 512)\n",
                "\n",
                "def feature_extract(data, spr):\n",
                "    n, l = data.shape[:]\n",
                "    feature_vectors = []\n",
                "    hw = np.hamming(l)  \n",
                "    for i in range(0, n):\n",
                "        sig = data[i]\n",
                "        #sig = nor(sig)\n",
                "        sig = sig - np.mean(sig)\n",
                "        sig = sig * hw\n",
                "        #fea = MFCC(sig, filter_banks)\n",
                "        fea = stas_feature4(sig, spr)\n",
                "        feature_vectors.append(fea)\n",
                "    return feature_vectors   \n",
                "\n",
                "def scaling(path):\n",
                "    no_snoring = np.load(path)\n",
                "    data = np.concatenate([no_snoring[0], no_snoring[2], no_snoring[4], no_snoring[6], no_snoring[8], no_snoring[10]])\n",
                "    l = data.shape[0]\n",
                "    hw = np.hamming(l)\n",
                "    data = data * hw\n",
                "    yf = fft(data)\n",
                "    yf = yf[:l//2]\n",
                "    energy = 1/(l)*np.abs(yf)\n",
                "    return np.mean(energy)\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "markdown",
            "source": [
                "# Machine Learning"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "import numpy as np\n",
                "from sklearn import svm\n",
                "from sklearn.naive_bayes import GaussianNB\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.mixture import GaussianMixture\n",
                "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "import os\n",
                "import time\n",
                "import pickle\n",
                "import random"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "def train(file_name):\n",
                "    \n",
                "    snoring_fea_vecs = np.load(path + \"/feature/snoring_\" + file_name + \".npy\")\n",
                "    no_snoring_fea_vecs = np.load(path + \"/feature/non_snoring_\" + file_name  + \".npy\")\n",
                "    n1 = snoring_fea_vecs.shape[0]\n",
                "    n2 = no_snoring_fea_vecs.shape[0]\n",
                "    n2 = int(n1)\n",
                "    print(n1, n2)\n",
                "\n",
                "    settings = \"model\" + file_name\n",
                "\n",
                "    np.random.shuffle(snoring_fea_vecs)\n",
                "    np.random.shuffle(no_snoring_fea_vecs)\n",
                "\n",
                "    X = np.concatenate([snoring_fea_vecs, no_snoring_fea_vecs[:n2]], axis=0)\n",
                "    Y = [0]*n1 + [1]*n2\n",
                "    t1 = time.time()\n",
                "    #SVM linear\n",
                "    clf = svm.SVC(C = 100, kernel='rbf', gamma='scale')\n",
                "    clf.fit(X,Y)\n",
                "    pickle.dump(clf, open(path + \"/model/\" + settings + \"/stats_model_SVM_linear.w\",'wb')) \n",
                "\n",
                "    #train NB\n",
                "    # clf = GaussianNB()\n",
                "    # clf.fit(X, Y)\n",
                "    # pickle.dump(clf, open(path + \"/model/\" + settings + \"/model_NB.w\",'wb'))\n",
                "\n",
                "    #logistic\n",
                "    # clf = LogisticRegression(random_state=0, solver='lbfgs')\n",
                "    # clf.fit(X, Y)\n",
                "    # pickle.dump(clf, open(path + \"/model/\" + settings + \"/model_LR.w\",'wb'))\n",
                "\n",
                "    #tree\n",
                "    # clf = DecisionTreeClassifier()\n",
                "    # clf.fit(X, Y)\n",
                "    # pickle.dump(clf, open(path + \"/model/\" + settings + \"/model_DT.w\",'wb'))\n",
                "\n",
                "    #LDA\n",
                "    # clf = LinearDiscriminantAnalysis()\n",
                "    # clf.fit(X, Y)\n",
                "    # pickle.dump(clf, open(path + \"/model/\" + settings + \"/model_LDA.w\",'wb'))\n",
                "\n",
                "    #GMM\n",
                "    # clf = GaussianMixture(n_components=2)\n",
                "    # clf.fit(X)\n",
                "    # pickle.dump(clf, open(path + \"/model/\" + settings + \"/model_GMM.w\",'wb'))\n",
                "\n",
                "    t2 = time.time()\n",
                "    print(\"training time:\", t2-t1)\n",
                "\n",
                "    t1 = time.time()\n",
                "    r1 = np.sum(1-clf.predict(snoring_fea_vecs[:n1]))/(n1)\n",
                "    if(r1 < 0.5):\n",
                "        r1 = 1 - r1\n",
                "    print(\"T\", r1)\n",
                "    n2 = no_snoring_fea_vecs.shape[0]\n",
                "    r2 = np.sum(clf.predict(no_snoring_fea_vecs[:n2]))/(n2)\n",
                "    if(r2 < 0.5):\n",
                "        r2 = 1 - r2\n",
                "    print(\"F\", r2)\n",
                "    t2 = time.time()\n",
                "    print(\"testing time:\", (t2-t1))\n",
                "\n",
                "for i in [1, 4, 5, 7, 8, 9]:\n",
                "    train(str(i))"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.6.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.6.9 64-bit ('icdsp': venv)"
        },
        "interpreter": {
            "hash": "2024ecb5b04f93d48b9d292488528cdff608cb43e64e84685cb2c31f324ec92c"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}